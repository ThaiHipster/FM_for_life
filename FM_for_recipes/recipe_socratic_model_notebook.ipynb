{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs if requirements.txt is not used\n",
    "# !pip install google-api-python-client\n",
    "# !pip install openai ftfy #what does ftfy mean\n",
    "# !pip install ffmpeg #audio library \n",
    "# !pip install pillow #audio library \n",
    "# !pip install recipe-scrapers\n",
    "# !pip install git+https://github.com/openai/whisper.git\n",
    "# !pip install wavio\n",
    "# !pip install scipy\n",
    "# !pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Open AI Key\n",
    "open_api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Voice to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Key Imports\n",
    "import numpy as np #array management\n",
    "import openai #openai api\n",
    "import pandas as pd #data management\n",
    "import pickle # model saving\n",
    "import torch\n",
    "import requests\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import io\n",
    "from recipe_scrapers import scrape_me\n",
    "\n",
    "# Setting the api key\n",
    "openai.api_key = open_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports for Voice AI Assistant\n",
    "\n",
    "import subprocess\n",
    "import wolframalpha\n",
    "import pyttsx3\n",
    "import tkinter\n",
    "import json\n",
    "import random\n",
    "import operator\n",
    "import speech_recognition as sr\n",
    "import datetime\n",
    "import wikipedia\n",
    "import webbrowser\n",
    "import os\n",
    "import winshell\n",
    "import pyjokes\n",
    "import feedparser\n",
    "import smtplib\n",
    "import ctypes\n",
    "import time\n",
    "import requests\n",
    "import shutil\n",
    "from twilio.rest import Client\n",
    "from clint.textui import progress\n",
    "from ecapture import ecapture as ec\n",
    "from bs4 import BeautifulSoup\n",
    "import win32com.client as wincl\n",
    "from urllib.request import urlopen\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting speach engine\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[1].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining speach function\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microphone with name \"Microsoft Sound Mapper - Input\" found for `Microphone(device_index=0)`\n",
      "Microphone with name \"Microphone Array (Realtek High \" found for `Microphone(device_index=1)`\n",
      "Microphone with name \"Microsoft Sound Mapper - Output\" found for `Microphone(device_index=2)`\n",
      "Microphone with name \"Speaker/HP (Realtek High Defini\" found for `Microphone(device_index=3)`\n",
      "Microphone with name \"Primary Sound Capture Driver\" found for `Microphone(device_index=4)`\n",
      "Microphone with name \"Microphone Array (Realtek High Definition Audio(SST))\" found for `Microphone(device_index=5)`\n",
      "Microphone with name \"Primary Sound Driver\" found for `Microphone(device_index=6)`\n",
      "Microphone with name \"Speaker/HP (Realtek High Definition Audio(SST))\" found for `Microphone(device_index=7)`\n",
      "Microphone with name \"Speaker/HP (Realtek High Definition Audio(SST))\" found for `Microphone(device_index=8)`\n",
      "Microphone with name \"Microphone Array (Realtek High Definition Audio(SST))\" found for `Microphone(device_index=9)`\n",
      "Microphone with name \"Speakers ()\" found for `Microphone(device_index=10)`\n",
      "Microphone with name \"Speakers 1 (Realtek HD Audio output with SST)\" found for `Microphone(device_index=11)`\n",
      "Microphone with name \"Speakers 2 (Realtek HD Audio output with SST)\" found for `Microphone(device_index=12)`\n",
      "Microphone with name \"PC Speaker (Realtek HD Audio output with SST)\" found for `Microphone(device_index=13)`\n",
      "Microphone with name \"Microphone Array (Realtek HD Audio Mic input)\" found for `Microphone(device_index=14)`\n",
      "Microphone with name \"Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Robertâ€™s AirPods Pro))\" found for `Microphone(device_index=15)`\n",
      "Microphone with name \"Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Robertâ€™s AirPods Pro))\" found for `Microphone(device_index=16)`\n",
      "Microphone with name \"Headphones ()\" found for `Microphone(device_index=17)`\n"
     ]
    }
   ],
   "source": [
    "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(\"Microphone with name \\\"{1}\\\" found for `Microphone(device_index={0})`\".format(index, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wishMe():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour>= 0 and hour<12:\n",
    "        speak(\"Good Morning Sir !\")\n",
    "  \n",
    "    elif hour>= 12 and hour<18:\n",
    "        speak(\"Good Afternoon Sir !\")  \n",
    "  \n",
    "    else:\n",
    "        speak(\"Good Evening Sir !\") \n",
    "  \n",
    "    assname =(\"Jarvis 1 point o\")\n",
    "    speak(\"I am your Assistant\")\n",
    "    speak(assname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def username():\n",
    "    speak(\"What should i call you sir\")\n",
    "    uname = takeCommand()\n",
    "    speak(\"Welcome Mister\")\n",
    "    speak(uname)\n",
    "    columns = shutil.get_terminal_size().columns\n",
    "     \n",
    "    print(\"#####################\".center(columns))\n",
    "    print(\"Welcome Mr.\", uname.center(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def takeCommand():\n",
    "    sr.Microphone(device_index=3) \n",
    "    r = sr.Recognizer()\n",
    "     \n",
    "    with sr.Microphone() as source:\n",
    "         \n",
    "        print(\"Listening...\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source)\n",
    "  \n",
    "    try:\n",
    "        print(\"Recognizing...\")   \n",
    "        query = r.recognize_google(audio, language ='en-in')\n",
    "        print(f\"User said: {query}\\n\")\n",
    "  \n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        print(\"Unable to Recognize your voice.\") \n",
    "        return \"None\"\n",
    "     \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_llm(prompt, max_tokens=64, temperature=0, stop=None):\n",
    "  response = openai.Completion.create(\n",
    "    model=gpt_version,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=top_p,\n",
    "    frequency_penalty=frequency_penalty,\n",
    "    presence_penalty=presence_penalty)\n",
    "  return response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing...\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.94278717,\n",
      "                           'transcript': \"hey you know I'm just going to talk \"\n",
      "                                         'about my day and I hope that '\n",
      "                                         'everyone will love how I talk about '\n",
      "                                         'my day'},\n",
      "                       {   'transcript': \"hey now I'm just going to talk about \"\n",
      "                                         'my day and I hope that everyone will '\n",
      "                                         'love how I talk about my day'},\n",
      "                       {   'transcript': \"hey you know I'm just going to talk \"\n",
      "                                         'about my day and I hope that '\n",
      "                                         'everyone will love how to talk about '\n",
      "                                         'my day'},\n",
      "                       {   'transcript': \"hey and I'm just going to talk about \"\n",
      "                                         'my day and I hope that everyone will '\n",
      "                                         'love how I talk about my day'},\n",
      "                       {   'transcript': \"hey you know I'm just going to talk \"\n",
      "                                         'about my day and I hope that '\n",
      "                                         'everyone will love her talk about my '\n",
      "                                         'day'}],\n",
      "    'final': True}\n",
      "User said: hey you know I'm just going to talk about my day and I hope that everyone will love how I talk about my day\n",
      "\n",
      "hey you know I'm just going to talk about my day and I hope that everyone will love how I talk about my day\n"
     ]
    }
   ],
   "source": [
    "# Take Command test code\n",
    "test = takeCommand()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Not Working) Send Emails - To Be Fixed\n",
    "def sendEmail(to, content):\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "     \n",
    "    # Enable low security in gmail\n",
    "    server.login('robert.a.alward@gmail.com', 'easypassword')\n",
    "    server.sendmail('robert.a.alward@gmail.com', to, content)\n",
    "    server.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sendEmail(\"rba_36@georgetown.edu\", \"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 8\u001b[0m, in \u001b[0;36mtakeCommand\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     r\u001b[39m.\u001b[39mpause_threshold \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     audio \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mlisten(source)\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Robert Alward\\.conda\\envs\\fm_for_life\\lib\\site-packages\\speech_recognition\\__init__.py:651\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(source, AudioSource), \u001b[39m\"\u001b[39m\u001b[39mSource must be an audio source\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 651\u001b[0m \u001b[39massert\u001b[39;00m source\u001b[39m.\u001b[39mstream \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mAudio source must be entered before listening, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpause_threshold \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnon_speaking_duration \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Audio source must be entered before listening, see documentation for ``AudioSource``; are you using ``source`` outside of a ``with`` statement?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# AI Assistant Programm Runtime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m wishMe()\n\u001b[1;32m----> 4\u001b[0m username()\n\u001b[0;32m      5\u001b[0m takeCommand()\n",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m, in \u001b[0;36musername\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39musername\u001b[39m():\n\u001b[0;32m     18\u001b[0m     speak(\u001b[39m\"\u001b[39m\u001b[39mWhat should i call you sir\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m     uname \u001b[39m=\u001b[39m takeCommand()\n\u001b[0;32m     20\u001b[0m     speak(\u001b[39m\"\u001b[39m\u001b[39mWelcome Mister\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     speak(uname)\n",
      "Cell \u001b[1;32mIn[34], line 8\u001b[0m, in \u001b[0;36mtakeCommand\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mListening...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     r\u001b[39m.\u001b[39mpause_threshold \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     audio \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mlisten(source)\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRecognizing...\u001b[39m\u001b[39m\"\u001b[39m)   \n",
      "File \u001b[1;32mc:\\Users\\Robert Alward\\.conda\\envs\\fm_for_life\\lib\\site-packages\\speech_recognition\\__init__.py:201\u001b[0m, in \u001b[0;36mMicrophone.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[0;32m    200\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mclose()\n\u001b[0;32m    202\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "# AI Assistant Programm Runtime\n",
    "\n",
    "wishMe()\n",
    "username()\n",
    "takeCommand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Assistant Full Run\n",
    "if __name__ == '__main__':\n",
    "    clear = lambda: os.system('cls')\n",
    "     \n",
    "    # This Function will clean any\n",
    "    # command before execution of this python file\n",
    "    clear()\n",
    "    wishMe()\n",
    "    username()\n",
    "     \n",
    "    while True:\n",
    "         \n",
    "        query = takeCommand().lower()\n",
    "         \n",
    "        # All the commands said by user will be\n",
    "        # stored here in 'query' and will be\n",
    "        # converted to lower case for easily\n",
    "        # recognition of command\n",
    "        if 'wikipedia' in query:\n",
    "            speak('Searching Wikipedia...')\n",
    "            query = query.replace(\"wikipedia\", \"\")\n",
    "            results = wikipedia.summary(query, sentences = 3)\n",
    "            speak(\"According to Wikipedia\")\n",
    "            print(results)\n",
    "            speak(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikapedia Module\n",
    "if 'wikipedia' in query:\n",
    "    speak('Searching Wikipedia...')\n",
    "    query = query.replace(\"wikipedia\", \"\")\n",
    "    results = wikipedia.summary(query, sentences = 3)\n",
    "    speak(\"According to Wikipedia\")\n",
    "    print(results)\n",
    "    speak(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Orchestration Module\n",
    "\n",
    "general_prompt = \"Given the following text:\" + user_request_input +\n",
    "\",and the options to cook food, google a question, find a wikapedia page, get a direct answer, write and email, or do a task, what do you think the user want to do\"\n",
    "prompt_llm(Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing...\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.96143973,\n",
      "                           'transcript': 'I would like to make a chicken base '\n",
      "                                         'dish tonight'},\n",
      "                       {   'transcript': 'I would like to make a chicken based '\n",
      "                                         'dish tonight'},\n",
      "                       {   'transcript': 'I would like to make a chicken bait '\n",
      "                                         'dish tonight'},\n",
      "                       {   'transcript': 'I would like to make a chicken bake '\n",
      "                                         'dish tonight'},\n",
      "                       {   'transcript': 'I would like to make a chicken bass '\n",
      "                                         'dish tonight'}],\n",
      "    'final': True}\n",
      "User said: I would like to make a chicken base dish tonight\n",
      "\n",
      "I would like to make a chicken base dish tonight\n",
      "salt, chicken, olive oil, butter, bread, kimchi, green onions\n"
     ]
    }
   ],
   "source": [
    "#1. (recipe) Audio to Text module\n",
    "\n",
    "input_auto = takeCommand()\n",
    "\n",
    "def ask_about_recipe(querry):\n",
    "    recipe_prompt = \"Given the following text:\" + user_request_input + \"what recipe does the user want to make?\"\n",
    "    recipe_querry = prompt_llm(recipe_prompt)\n",
    "    \"I heard you say that you want to make\" + recipe_querry\n",
    "    if takeCommand() == \"yes\":\n",
    "        \"Great, Do you have any restrictions on the meal\"\n",
    "        restrictions = takeCommand()\n",
    "        \"Great, any other notes about the meal?\"\n",
    "        meal_notes = takeCommand()\n",
    "        full_recipe_prompt = \"Given that a home chef wants to make\" + recipe_querry +\n",
    "        \"and they have the following restrictions\" + restrictions + \"and it is important to consider \" +\n",
    "        meal_notes + \"What would you look up to make\"\n",
    "        full_recipe_querry = prompt_llm(full_recipe_prompt)\n",
    "    else: \n",
    "        \"Sorry for the incorect summary, what would you like to do\"\n",
    "    return full_recipe_querry    \n",
    "\n",
    "# Recipe check\n",
    "ask_about_recipe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Text to Text: Google Search Prompt\n",
    "List item\n",
    "List item\n",
    "To Do: pressure test the prompt outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recipe Text to Search: Hyperparameters\n",
    "gpt_version = \"text-davinci-003\"\n",
    "temperature = .5\n",
    "max_tokens = 60\n",
    "top_p = 1\n",
    "frequency_penalty = 0.8\n",
    "presence_penalty =0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing: Input Text to Google Search\n",
    "\n",
    "# choosing the hyperparameters for GPT-3 and getting the text out of the LLM\n",
    "def prompt_llm(prompt, max_tokens=64, temperature=0, stop=None):\n",
    "  response = openai.Completion.create(\n",
    "    model=gpt_version,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=top_p,\n",
    "    frequency_penalty=frequency_penalty,\n",
    "    presence_penalty=presence_penalty)\n",
    "  return response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input Text to Google Search Model prompting\n",
    "prompt = \"Extract keywords from this text:\"\n",
    "prompt = f'{full_recipe_querry}'\n",
    "\n",
    "gpt_search_output = prompt_llm(prompt)\n",
    "print(gpt_search_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Text to Search: Google Search Componenet\n",
    "- To Do: Get the images and descriptions seperated from the search results\n",
    "- Plug in the text *search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Text to Search: Google Search Module\n",
    "# API and CSE Key for Google Search\n",
    "my_api_key = \"AIzaSyBIBeS6Wtx7jEVPgdr2D2nqRowrBtukUaM\"\n",
    "my_cse_id = \"f0355dc0a7c1d488a\"\n",
    "\n",
    "# Google Search function\n",
    "def google_search(search_term, api_key, cse_id, **kwargs):\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    res = service.cse().list(q=search_term, cx=cse_id, **kwargs).execute()\n",
    "    return res['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Running Google Search\n",
    "results = google_search(\n",
    "    f'{gpt_search_output}', my_api_key, my_cse_id, num=10)\n",
    "\n",
    "i = 1\n",
    "google_search_number = []\n",
    "\n",
    "recipes = []\n",
    "for result in results:\n",
    "    recipes.append(result)\n",
    "    google_search_number.append(i)\n",
    "    i = i +1\n",
    "\n",
    "\n",
    "\n",
    "pprint.pprint(recipes[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Search to Image: Google Search to Image\n",
    "- To Do: run through the image loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (Example) Getting a link from the first page\n",
    "image_link = results[0]['pagemap']['metatags'][0]['og:image']\n",
    "#pprint.pprint(results[0]['pagemap']['metatags'][0]['og:image'])\n",
    "response = requests.get(image_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Search to Image: Function to get the image from the google search\n",
    "def image_from_search(id_num):\n",
    "    image_link_1 = results[id_num]['pagemap']['metatags'][0]['og:image']\n",
    "    image_link_2 = results[id_num]['pagemap']['metatags'][0]['og:image']\n",
    "    image_link_3 = results[id_num]['pagemap']['metatags'][0]['og:image']\n",
    "\n",
    "    if image_link_1 == picture:\n",
    "        image = image_link_1\n",
    "    elif image_link_2 == picture:\n",
    "        image = image_link_2\n",
    "    elif image_link_2 == picture:\n",
    "        image = image_link_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the list of google search results\n",
    "\n",
    "### Looped image display\n",
    "num = [0,1,2,3,4,5]\n",
    "\n",
    "for i in num:\n",
    "  print(i)\n",
    "  image_link = results[i]['pagemap']['metatags'][0]['og:image']\n",
    "  response = requests.get(image_link)\n",
    "\n",
    "  print(results[i]['title'])\n",
    "  print(results[i]['snippet'])\n",
    "  print(results[i]['pagemap']['metatags'][0]['og:description'])\n",
    "\n",
    "img = Image.open(io.BytesIO(response.content)).resize((256, 256))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Printing the title, summary, and image\n",
    "\n",
    "# Opening image\n",
    "img = Image.open(io.BytesIO(response.content)).resize((256, 256))\n",
    "\n",
    "print(results[0]['title'])\n",
    "print(results[0]['snippet'])\n",
    "print(results[0]['pagemap']['metatags'][0]['og:description'])\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Web Scrape of Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for recipe web scrapping\n",
    "from recipe_scrapers import scrape_me\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the URL\n",
    "#https://www.thepioneerwoman.com/food-cooking/recipes/a96094/crispy-chicken-florentine-melt/\n",
    "# website_link = results[0]['formattedUrl']\n",
    "website_link = \"https://www.thepioneerwoman.com/food-cooking/recipes/a96094/crispy-chicken-florentine-melt/\"\n",
    "print(website_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.thepioneerwoman.com/food-cooking/recipes/a96094/crispy-chicken-florentine-melt/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "text1 = soup.find_all('div', attrs={'ingredients-body': 'css-0 eno1xhi5'})\n",
    "\n",
    "#<div class=\"ingredients-body css-0 eno1xhi5\">\n",
    "print(text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 6. Text Assist from the web scrape of the recipe\n",
    "Z. Archive of Text\n",
    "1. More extended accessing of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# get list of MP3 audio files\n",
    "paths = [str(x) for x in Path('./mp3').glob('*.mp3')]\n",
    "print(len(paths))\n",
    "print(paths[:5])\n",
    "108\n",
    "['mp3/35Pdoyi6ZoQ.mp3', 'mp3/B7wmo_NImgM.mp3', 'mp3/x1lAcT3xl5M.mp3', 'mp3/r-zQQ16wTCA.mp3', 'mp3/DFtP1THE8fE.mp3']\n",
    "\n",
    "# we get the IDs like so\n",
    "paths[0].split('/')[-1][:-4]\n",
    "'35Pdoyi6ZoQ'\n",
    "data = []\n",
    "\n",
    "for i, path in enumerate(tqdm(paths)):\n",
    "    _id = path.split('/')[-1][:-4]\n",
    "    # transcribe to get speech-to-text data\n",
    "    result = model.transcribe(path)\n",
    "    # add results to data list\n",
    "    data.extend(result['segments'])\n",
    "    break  # this is just part of the loop used as example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fm_for_life",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d86eac2452d61c4b3d921e3dde4e9f1e353488f9c1d5178d80b9e079a325af1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
