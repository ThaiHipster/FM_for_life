{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Open AI Key\n",
    "open_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for recipe web scrapping\n",
    "from recipe_scrapers import scrape_me\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import json\n",
    "import os\n",
    "import os\n",
    "\n",
    "import io\n",
    "import random\n",
    "import win32com.client as wincl\n",
    "import winshell\n",
    "\n",
    "\n",
    "# Key Imports\n",
    "import numpy as np #array management\n",
    "import pandas as pd #data management\n",
    "import pickle # model saving\n",
    "import requests\n",
    "import requests\n",
    "\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# AI Imports\n",
    "import torch\n",
    "import openai #openai api\n",
    "\n",
    "# Utilities\n",
    "from PIL import Image\n",
    "from recipe_scrapers import scrape_me\n",
    "import json\n",
    "import time\n",
    "from twilio.rest import Client\n",
    "import operator\n",
    "import datetime\n",
    "\n",
    "# Plug-Ins\n",
    "import wolframalpha\n",
    "import pyjokes\n",
    "import wikipedia\n",
    "import webbrowser\n",
    "\n",
    "# Speech Recognition\n",
    "import pyaudio\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Web Scraping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Other\n",
    "import subprocess\n",
    "import pyttsx3\n",
    "import tkinter\n",
    "import feedparser\n",
    "import smtplib\n",
    "import ctypes\n",
    "import shutil\n",
    "from clint.textui import progress\n",
    "from ecapture import ecapture as ec\n",
    "\n",
    "# Setting the api key\n",
    "openai.api_key = open_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Voice to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting speach engine\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[1].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining speach function\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining introduction function\n",
    "def wishMe():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour>= 0 and hour<12:\n",
    "        speak(\"Good Morning Sir !\")\n",
    "  \n",
    "    elif hour>= 12 and hour<18:\n",
    "        speak(\"Good Afternoon Sir !\")  \n",
    "  \n",
    "    else:\n",
    "        speak(\"Good Evening Sir !\") \n",
    "  \n",
    "    assname =(\"Jarvis 1 point o\")\n",
    "    speak(\"I am your Assistant\")\n",
    "    speak(assname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name definition function\n",
    "def username():\n",
    "    speak(\"What should i call you sir\")\n",
    "    uname = takeCommand()\n",
    "    speak(\"Welcome Mister\")\n",
    "    speak(uname)\n",
    "    columns = shutil.get_terminal_size().columns\n",
    "     \n",
    "    print(\"#####################\".center(columns))\n",
    "    print(\"Welcome Mr.\", uname.center(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take the command from the person\n",
    "def takeCommand():\n",
    "    sr.Microphone(device_index=3) \n",
    "    r = sr.Recognizer()\n",
    "     \n",
    "    with sr.Microphone() as source:\n",
    "         \n",
    "        print(\"Listening...\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source)\n",
    "  \n",
    "    try:\n",
    "        print(\"Recognizing...\")   \n",
    "        query = r.recognize_google(audio, language ='en-in')\n",
    "        print(f\"User said: {query}\\n\")\n",
    "  \n",
    "    except Exception as e:\n",
    "        print(e)   \n",
    "        print(\"Unable to Recognize your voice.\") \n",
    "        return \"None\"\n",
    "     \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defining GPT-3 prompted model\n",
    "def prompt_llm(prompt, max_tokens=64, temperature=0, stop=None):\n",
    "  response = openai.Completion.create(\n",
    "    model=gpt_version,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=top_p,\n",
    "    frequency_penalty=frequency_penalty,\n",
    "    presence_penalty=presence_penalty)\n",
    "  return response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing: Input Text to Google Search\n",
    "\n",
    "# choosing the hyperparameters for GPT-3 and getting the text out of the LLM\n",
    "def prompt_llm(prompt, max_tokens=64, temperature=0, stop=None):\n",
    "  response = openai.Completion.create(\n",
    "    model=gpt_version,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=top_p,\n",
    "    frequency_penalty=frequency_penalty,\n",
    "    presence_penalty=presence_penalty)\n",
    "  return response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Email Sending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Not Working) Send Emails - To Be Fixed\n",
    "def sendEmail(to, content):\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "     \n",
    "    # Enable low security in gmail\n",
    "    server.login('robert.a.alward@gmail.com', 'easypassword')\n",
    "    server.sendmail('robert.a.alward@gmail.com', to, content)\n",
    "    server.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Recipe Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recipe: Text to Search - Hyperparameters\n",
    "gpt_version = \"text-davinci-003\"\n",
    "temperature = .5\n",
    "max_tokens = 60\n",
    "top_p = 1\n",
    "frequency_penalty = 0.8\n",
    "presence_penalty =0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3091399129.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 26\u001b[1;36m\u001b[0m\n\u001b[1;33m    return full_recipe_querry\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Recipe: Querry function\n",
    "def ask_about_recipe(user_request_input):\n",
    "    speak(user_request_input)\n",
    "    # Recipe prompt\n",
    "    f'{full_recipe_querry}'\n",
    "    intro = \"Given the following text:\"\n",
    "    question = \"what recipe does the user want to make?\"\n",
    "    recipe_prompt = intro + user_request_input + question\n",
    "    recipe_querry = prompt_llm(recipe_prompt)\n",
    "\n",
    "    # Recipe respones\n",
    "    print(f\"User said: {query}\\n\")\n",
    "\n",
    "    speak(f\"I heard you say that you want to make {recipe_querry}\")\n",
    "    speak(\"Is this what you want to make?\")\n",
    "         \n",
    "    query = takeCommand().lower()\n",
    "    # Recipe feedback\n",
    "    if 'yes' in query:\n",
    "        speak(\"Great, Do you have any restrictions on the meal\")\n",
    "        restrictions = takeCommand().lower()\n",
    "        speak(\"Great, any other notes about the meal?\")\n",
    "        notes = takeCommand().lower()\n",
    "        full_recipe_prompt = f\"Given that a home chef wants to make {recipe_querry} and they have the following restrictions {restrictions} and it is important to consider {meal_notes} What would you look up to make\"\n",
    "        full_recipe_querry = prompt_llm(full_recipe_prompt)\n",
    "        return full_recipe_querry    \n",
    "    else: \n",
    "        \"Sorry for the incorect summary, what would you like to make\"\n",
    "        update_query = takeCommand().lower()\n",
    "        return ask_about_recipe(update_query)\n",
    "    \n",
    "test = \"I want to make a chocolate cake\"\n",
    "ask_about_recipe(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. GPT Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3355227713.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    general_prompt = \"Given the following text:\" + user_request_input +\u001b[0m\n\u001b[1;37m                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# GPT Orchestration Module\n",
    "def GPT_orchestration_module(user_request_input):\n",
    "    general_prompt = \"Given the following text:\" + user_request_input + \",and the options to cook food, google a question, find a wikapedia page, get a direct answer, write and email, or do a task, what do you think the user want to do\"\n",
    "    gpt_ochestration_response = prompt_llm(general_prompt)\n",
    "    return gpt_orchestration_response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Google Search: \n",
    "\n",
    "- To Do: pressure test the prompt outcomes\n",
    "- To Do: Get the images and descriptions seperated from the search results\n",
    "- Plug in the text *search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search: Search Input Utils\n",
    "# API and CSE Key for Google Search\n",
    "my_api_key = \"AIzaSyBIBeS6Wtx7jEVPgdr2D2nqRowrBtukUaM\"\n",
    "my_cse_id = \"f0355dc0a7c1d488a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search: Search Prompt: Input Text to Google Search Model prompting\n",
    "prompt = \"Extract keywords from this text:\"\n",
    "prompt = f'{full_recipe_querry}'\n",
    "\n",
    "gpt_search_output = prompt_llm(prompt)\n",
    "print(gpt_search_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search: Text to Search: Google Search Module\n",
    "# Google Search function\n",
    "def google_search(search_term, api_key, cse_id, **kwargs):\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    res = service.cse().list(q=search_term, cx=cse_id, **kwargs).execute()\n",
    "    return res['items']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Search: Image, Title, and Hyperparameter Extraction\n",
    "- To Do: make function to extract image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Search to Image: Function to get the image from the google search\n",
    "def info_from_search(id_num):\n",
    "    image_link_1 = results[id_num]['pagemap']['metatags'][0]['og:image']\n",
    "    image_link_2 = results[id_num]['pagemap']['metatags'][0]['og:image']\n",
    "    image_link_3 = results[id_num]['pagemap']['metatags'][0]['og:image']\n",
    "\n",
    "    if image_link_1 == picture:\n",
    "        image = image_link_1\n",
    "    elif image_link_2 == picture:\n",
    "        image = image_link_2\n",
    "    elif image_link_2 == picture:\n",
    "        image = image_link_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 5. Webscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.thepioneerwoman.com/food-cooking/recipes/a96094/crispy-chicken-florentine-melt/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "text1 = soup.find_all('div', attrs={'ingredients-body': 'css-0 eno1xhi5'})\n",
    "\n",
    "#<div class=\"ingredients-body css-0 eno1xhi5\">\n",
    "print(text1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Commands and Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Introduction Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General: AI Assistant Full Run\n",
    "if __name__ == '__main__':\n",
    "    clear = lambda: os.system('cls')\n",
    "     \n",
    "    # This Function will clean any\n",
    "    # command before execution of this python file\n",
    "    clear()\n",
    "    wishMe()\n",
    "    username()\n",
    "     \n",
    "    while True:\n",
    "         \n",
    "        query = takeCommand().lower()\n",
    "         \n",
    "        # All the commands said by user will be\n",
    "        # stored here in 'query' and will be\n",
    "        # converted to lower case for easily\n",
    "        # recognition of command\n",
    "        if 'wikipedia' in query:\n",
    "            speak('Searching Wikipedia...')\n",
    "            query = query.replace(\"wikipedia\", \"\")\n",
    "            results = wikipedia.summary(query, sentences = 3)\n",
    "            speak(\"According to Wikipedia\")\n",
    "            print(results)\n",
    "            speak(results)\n",
    "            \n",
    "        sendEmail(\"rba_36@georgetown.edu\", \"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recipe: Audio to Text module\n",
    "input_auto = takeCommand()\n",
    "\n",
    "# Recipe check\n",
    "ask_about_recipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search: Running Google Search\n",
    "results = google_search(\n",
    "    f'{gpt_search_output}', my_api_key, my_cse_id, num=10)\n",
    "\n",
    "i = 1\n",
    "google_search_number = []\n",
    "\n",
    "recipes = []\n",
    "for result in results:\n",
    "    recipes.append(result)\n",
    "    google_search_number.append(i)\n",
    "    i = i +1\n",
    "\n",
    "pprint.pprint(recipes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search to Image: Getting a link from the first page\n",
    "image_link = results[0]['pagemap']['metatags'][0]['og:image']\n",
    "#pprint.pprint(results[0]['pagemap']['metatags'][0]['og:image'])\n",
    "response = requests.get(image_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search to Image: Get the list of google search results\n",
    "### Looped image display\n",
    "num = [0,1,2,3,4,5]\n",
    "\n",
    "for i in num:\n",
    "  print(i)\n",
    "  image_link = results[i]['pagemap']['metatags'][0]['og:image']\n",
    "  response = requests.get(image_link)\n",
    "\n",
    "  print(results[i]['title'])\n",
    "  print(results[i]['snippet'])\n",
    "  print(results[i]['pagemap']['metatags'][0]['og:description'])\n",
    "\n",
    "img = Image.open(io.BytesIO(response.content)).resize((256, 256))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search to Image: Printing the title, summary, and image\n",
    "# Opening image\n",
    "img = Image.open(io.BytesIO(response.content)).resize((256, 256))\n",
    "\n",
    "print(results[0]['title'])\n",
    "print(results[0]['snippet'])\n",
    "print(results[0]['pagemap']['metatags'][0]['og:description'])\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the URL\n",
    "#https://www.thepioneerwoman.com/food-cooking/recipes/a96094/crispy-chicken-florentine-melt/\n",
    "# website_link = results[0]['formattedUrl']\n",
    "website_link = \"https://www.thepioneerwoman.com/food-cooking/recipes/a96094/crispy-chicken-florentine-melt/\"\n",
    "print(website_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archive Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# get list of MP3 audio files\n",
    "paths = [str(x) for x in Path('./mp3').glob('*.mp3')]\n",
    "print(len(paths))\n",
    "print(paths[:5])\n",
    "108\n",
    "['mp3/35Pdoyi6ZoQ.mp3', 'mp3/B7wmo_NImgM.mp3', 'mp3/x1lAcT3xl5M.mp3', 'mp3/r-zQQ16wTCA.mp3', 'mp3/DFtP1THE8fE.mp3']\n",
    "\n",
    "# we get the IDs like so\n",
    "paths[0].split('/')[-1][:-4]\n",
    "'35Pdoyi6ZoQ'\n",
    "data = []\n",
    "\n",
    "for i, path in enumerate(tqdm(paths)):\n",
    "    _id = path.split('/')[-1][:-4]\n",
    "    # transcribe to get speech-to-text data\n",
    "    result = model.transcribe(path)\n",
    "    # add results to data list\n",
    "    data.extend(result['segments'])\n",
    "    break  # this is just part of the loop used as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archive Code\n",
    "# Installs if requirements.txt is not used\n",
    "# !pip install google-api-python-client\n",
    "# !pip install openai ftfy #what does ftfy mean\n",
    "# !pip install ffmpeg #audio library \n",
    "# !pip install pillow #audio library \n",
    "# !pip install recipe-scrapers\n",
    "# !pip install git+https://github.com/openai/whisper.git\n",
    "# !pip install wavio\n",
    "# !pip install scipy\n",
    "# !pip install sounddevice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d86eac2452d61c4b3d921e3dde4e9f1e353488f9c1d5178d80b9e079a325af1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
